DenseNet:
	All the networks are trained using stochastic gradient descent (SGD). On CIFAR and SVHN we train using batch
	size 64 for 300 and 40 epochs, respectively. The initial
	learning rate is set to 0.1, and is divided by 10 at 50% and
	75% of the total number of training epochs. On ImageNet,
	we train models for 90 epochs with a batch size of 256.
	The learning rate is set to 0.1 initially, and is lowered by
	10 times at epoch 30 and 60. 